{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b010f5af",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9c645",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This report documents the wrangling efforts performed on 3 datasets extracted from social buzz site. Social buzz is a content platform that keeps users anonymous while tracking their reactions on every piece of content posted. These datasets are named Content.csv, Reactions.csv and ReactionTypes.csv\n",
    "Each of these datasets which are have characteristics of big data making them have data quality and tidiness issues as will be seen by their dirtiness and messiness. In a bid to inspect these dataset and fix these issues i will put these datasets through the wrangling process in a 3-fold step summarized as - \n",
    "- Gather\n",
    "- Assess and \n",
    "- Clean\n",
    "\n",
    "The result of this process will be a cleaned dataset.\n",
    "\n",
    "Note that the practical wrangling process is carried out in the wrangle_act social buzz.ipynb file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac306060",
   "metadata": {},
   "source": [
    "First i will import all the python packages required to successfully perform wrangling. The libraries required include: numpy, pandas, matplotlib, seaborn, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec1a73",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4189cd",
   "metadata": {},
   "source": [
    "Here, i read and loaded the 3 datasets into my pandas dataframe. \n",
    "- The Content.csv file stores information on the content posted -contentID, userid content url, content type and category.\n",
    "- The Reactions.csv file stores information on the reactions to each piece of content.It stores information on the content_id, userid, type of reaction and date and time in which the reaction was made It is hosted on Udacity's servers and \n",
    "- The ReactionsType.csv files contains information on the reactions type, their sentiment and their score which is a number calculated by social buzz to quantify how popular each reaction is.\n",
    "- These 3 datasets were extracted from social buzz site using SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c634978",
   "metadata": {},
   "source": [
    "### Data Assessing\n",
    "\n",
    "On successfully gathering all necessary data, assessing of data is carried out both Visually using Microsoft Excel spreadsheet program and Programmatically using codes. The following Quality and tidy issues were detected-\n",
    "\n",
    "#### Quality\n",
    "\n",
    "- Missing entries in `reactions`(User ID, Type) table\n",
    " - Wrong datatype for datetime in `reactions` table\n",
    " - Multiple representations of category data entry in `content` table - sometimes quotes, sometimes no quotes, sometimes lowercase, sometimes uppercase\n",
    " - Use of non-unique column names with varied values in `content` table(Type) and `reactions`/`reactiontypes`(Type) table\n",
    " - Non-descriptive column headers(Type in Content table and Type in Reactions table\n",
    " - Inconsistent column headers naming format- sometimes lower case, sometimes upper case(URL), whitespace in column headers (User ID)\n",
    " \n",
    "#### Tidiness\n",
    "- `reactions`, `reactiontypes` and `location` tables should be part of `content` table\n",
    "- Extraneous columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561672b",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "After a thorough assessment and detection of content and structural issues in the datasets, the cleaning process is carried out to fix each of these identified issues. \n",
    "\n",
    "Before commencing the cleaning process, the Content.csv, Reactions.csv and ReactionTypes.csv datasets consisted of 1000, 25,553 and 16 entries respectively. \n",
    "\n",
    "By the end of the cleaning process, they are merged into one dataset file called content_reaction and then stored in a file called socialbuzz_content_master.csv. This dataset consists of 24,573 entries with all the detected quality and tidiness issues resolved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
